device: 1
data:
  dataset: METR-LA
  batch-size: 64
  input_dim: 2
  output_dim: 1

train:
  epochs: 100
  early_stop_steps: null
  max_grad_norm: 5

optimizer:
  name: Adam
  Adam:
    lr: 0.001
    weight_decay: 0.0001
  RMSprop:
    lr: 0.001
    weight_decay: 0.0001

loss:
  name: MaskedMAELoss

model:
  name: Ours
  Ours:
    n_in: 2
    n_out: 1
    n_hidden: 32
    t_pred: 12
    n_blocks: 4
    n_layers: 3
    edge_dim: 2
    dropout: 0.0

scheduler:
  name: MultiStepLR
  ReduceLROnPlateau:
    factor: 0.5
    patience: 0
    threshold: 0.05
    min_lr: 0.00001
  StepLR:
    step_size: 10
    gamma: 0.1
  MultiStepLR:
    milestones: [20, 30, 40, 50]
    gamma: 0.1
  CosineAnnealingLR:
    T_max: 5
    eta_min: 0.0000001